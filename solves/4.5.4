import torch
import torch.nn as nn
import torch.utils.data as data

class WordsDataset(data.Dataset):
    def __init__(self, navec_emb, prev_words=4):
        self.prev_words = prev_words
        self.navec_emb = navec_emb

        self.lines = _global_var_text
        self.vocab = set((" ".join(self.lines)).lower().split())
        self.vocab_size = len(self.vocab)

        data = []
        targets = []

        for t in self.lines:
            words = t.lower().split()
            for item in range(len(words)-self.prev_words):
                data.append([self.navec_emb[words[x]].tolist() for x in range(item, item + self.prev_words)])
                targets.append(self.navec_emb.vocab[words[item+self.prev_words]])

        self.data = torch.tensor(data)
        self.targets = torch.tensor(targets)

        self.length = len(data)

    def __getitem__(self, item):
        return self.data[item], self.targets[item]

    def __len__(self):
        return self.length


d_train = WordsDataset(global_navec)
train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)
